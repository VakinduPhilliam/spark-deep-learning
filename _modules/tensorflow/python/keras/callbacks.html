
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>tensorflow.python.keras.callbacks &#8212; pysparkdl  documentation</title>
    <link rel="stylesheet" href="../../../../_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pysparkdl.css" type="text/css" />
    
    <script id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/language_data.js"></script>
    <script src="../../../../_static/pysparkdl.js"></script>
    
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
    
        <li class="nav-item nav-item-0"><a href="../../../../index.html">pysparkdl  documentation</a> &#187;</li>

          <li class="nav-item nav-item-1"><a href="../../../index.html" accesskey="U">Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">tensorflow.python.keras.callbacks</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for tensorflow.python.keras.callbacks</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2015 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="c1"># pylint: disable=g-import-not-at-top</span>
<span class="sd">&quot;&quot;&quot;Callbacks: utilities called at certain points during model training.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">six</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.data.ops</span> <span class="kn">import</span> <span class="n">iterator_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.distribute</span> <span class="kn">import</span> <span class="n">distributed_file_utils</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.distribute</span> <span class="kn">import</span> <span class="n">multi_worker_util</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.eager</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.distribute</span> <span class="kn">import</span> <span class="n">multi_worker_training_state</span> <span class="k">as</span> <span class="n">training_state</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.utils.data_utils</span> <span class="kn">import</span> <span class="n">Sequence</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.utils.generic_utils</span> <span class="kn">import</span> <span class="n">Progbar</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.utils.mode_keys</span> <span class="kn">import</span> <span class="n">ModeKeys</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.lib.io</span> <span class="kn">import</span> <span class="n">file_io</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="kn">import</span> <span class="n">array_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="kn">import</span> <span class="n">math_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="kn">import</span> <span class="n">summary_ops_v2</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="kn">import</span> <span class="n">variables</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.platform</span> <span class="kn">import</span> <span class="n">tf_logging</span> <span class="k">as</span> <span class="n">logging</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.training</span> <span class="kn">import</span> <span class="n">checkpoint_management</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util.compat</span> <span class="kn">import</span> <span class="n">collections_abc</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util.tf_export</span> <span class="kn">import</span> <span class="n">keras_export</span>
<span class="kn">from</span> <span class="nn">tensorflow.tools.docs</span> <span class="kn">import</span> <span class="n">doc_controls</span>

<span class="k">try</span><span class="p">:</span>
  <span class="kn">import</span> <span class="nn">requests</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
  <span class="n">requests</span> <span class="o">=</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">configure_callbacks</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span>
                        <span class="n">model</span><span class="p">,</span>
                        <span class="n">do_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">epochs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">count_mode</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">,</span>
                        <span class="n">mode</span><span class="o">=</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Configures callbacks for use in various training loops.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      callbacks: List of Callbacks.</span>
<span class="sd">      model: Model being trained.</span>
<span class="sd">      do_validation: Whether or not validation loop will be run.</span>
<span class="sd">      batch_size: Number of samples per batch.</span>
<span class="sd">      epochs: Number of epoch to train.</span>
<span class="sd">      steps_per_epoch: Number of batches to run per training epoch.</span>
<span class="sd">      samples: Number of training samples.</span>
<span class="sd">      verbose: int, 0 or 1. Keras logging verbosity to pass to ProgbarLogger.</span>
<span class="sd">      count_mode: One of &#39;steps&#39; or &#39;samples&#39;. Per-batch or per-sample count.</span>
<span class="sd">      mode: String. One of ModeKeys.TRAIN, ModeKeys.TEST, or ModeKeys.PREDICT.</span>
<span class="sd">        Which loop mode to configure callbacks for.</span>

<span class="sd">  Returns:</span>
<span class="sd">      Instance of CallbackList used to control all Callbacks.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># Check if callbacks have already been configured.</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">CallbackList</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">callbacks</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">callbacks</span><span class="p">:</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="c1"># Add additional callbacks during training.</span>
  <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="n">History</span><span class="p">()</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">BaseLogger</span><span class="p">()]</span> <span class="o">+</span> <span class="p">(</span><span class="n">callbacks</span> <span class="ow">or</span> <span class="p">[])</span> <span class="o">+</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
      <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ProgbarLogger</span><span class="p">(</span><span class="n">count_mode</span><span class="p">))</span>
  <span class="n">callback_list</span> <span class="o">=</span> <span class="n">CallbackList</span><span class="p">(</span><span class="n">callbacks</span><span class="p">)</span>

  <span class="c1"># Set callback model</span>
  <span class="n">callback_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">_get_callback_model</span><span class="p">()</span>  <span class="c1"># pylint: disable=protected-access</span>
  <span class="n">callback_list</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">callback_model</span><span class="p">)</span>

  <span class="n">set_callback_parameters</span><span class="p">(</span>
      <span class="n">callback_list</span><span class="p">,</span>
      <span class="n">model</span><span class="p">,</span>
      <span class="n">do_validation</span><span class="o">=</span><span class="n">do_validation</span><span class="p">,</span>
      <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
      <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
      <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>
      <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span>
      <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
      <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span>

  <span class="n">callback_list</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="k">return</span> <span class="n">callback_list</span>


<span class="k">def</span> <span class="nf">set_callback_parameters</span><span class="p">(</span><span class="n">callback_list</span><span class="p">,</span>
                            <span class="n">model</span><span class="p">,</span>
                            <span class="n">do_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">epochs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">mode</span><span class="o">=</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Sets callback parameters.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      callback_list: CallbackList instance.</span>
<span class="sd">      model: Model being trained.</span>
<span class="sd">      do_validation: Whether or not validation loop will be run.</span>
<span class="sd">      batch_size: Number of samples per batch.</span>
<span class="sd">      epochs: Number of epoch to train.</span>
<span class="sd">      steps_per_epoch: Number of batches to run per training epoch.</span>
<span class="sd">      samples: Number of training samples.</span>
<span class="sd">      verbose: int, 0 or 1. Keras logging verbosity to pass to ProgbarLogger.</span>
<span class="sd">      mode: String. One of ModeKeys.TRAIN, ModeKeys.TEST, or ModeKeys.PREDICT.</span>
<span class="sd">        Which loop mode to configure callbacks for.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">metric_names</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span>
  <span class="k">for</span> <span class="n">cbk</span> <span class="ow">in</span> <span class="n">callback_list</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cbk</span><span class="p">,</span> <span class="p">(</span><span class="n">BaseLogger</span><span class="p">,</span> <span class="n">ProgbarLogger</span><span class="p">)):</span>
      <span class="n">cbk</span><span class="o">.</span><span class="n">stateful_metrics</span> <span class="o">=</span> <span class="n">metric_names</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>  <span class="c1"># Exclude `loss`</span>

  <span class="c1"># Set callback parameters</span>
  <span class="n">callback_metrics</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="c1"># When we have deferred build scenario with iterator input, we will compile</span>
  <span class="c1"># when we standardize first batch of data.</span>
  <span class="k">if</span> <span class="n">mode</span> <span class="o">!=</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span><span class="p">:</span>
    <span class="n">callback_metrics</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">metric_names</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">do_validation</span><span class="p">:</span>
      <span class="n">callback_metrics</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;val_&#39;</span> <span class="o">+</span> <span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">metric_names</span><span class="p">]</span>
  <span class="n">callback_params</span> <span class="o">=</span> <span class="p">{</span>
      <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
      <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="n">epochs</span><span class="p">,</span>
      <span class="s1">&#39;steps&#39;</span><span class="p">:</span> <span class="n">steps_per_epoch</span><span class="p">,</span>
      <span class="s1">&#39;samples&#39;</span><span class="p">:</span> <span class="n">samples</span><span class="p">,</span>
      <span class="s1">&#39;verbose&#39;</span><span class="p">:</span> <span class="n">verbose</span><span class="p">,</span>
      <span class="s1">&#39;do_validation&#39;</span><span class="p">:</span> <span class="n">do_validation</span><span class="p">,</span>
      <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="n">callback_metrics</span><span class="p">,</span>
  <span class="p">}</span>
  <span class="n">callback_list</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">callback_params</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_is_generator_like</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Checks if data is a generator, Sequence, or Iterator.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;next&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__next__&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span>
      <span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">Sequence</span><span class="p">,</span> <span class="n">iterator_ops</span><span class="o">.</span><span class="n">Iterator</span><span class="p">,</span> <span class="n">iterator_ops</span><span class="o">.</span><span class="n">OwnedIterator</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">make_logs</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">logs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes logs for sending to `on_batch_end` methods.&quot;&quot;&quot;</span>
  <span class="n">metric_names</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span>
  <span class="k">if</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">{</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">}</span> <span class="ow">and</span> <span class="n">metric_names</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">metric_names</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
      <span class="n">logs</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">output</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">logs</span><span class="p">[</span><span class="s1">&#39;outputs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outputs</span>
  <span class="k">return</span> <span class="n">logs</span>


<span class="k">class</span> <span class="nc">CallbackList</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Container abstracting a list of callbacks.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      callbacks: List of `Callback` instances.</span>
<span class="sd">      queue_length: Queue length for keeping</span>
<span class="sd">          running statistics over callback execution time.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">queue_length</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks</span> <span class="ow">or</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">callbacks</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">queue_length</span> <span class="o">=</span> <span class="n">queue_length</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reset_batch_timing</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_reset_batch_timing</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_delta_t_batch</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_delta_ts</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span>
        <span class="k">lambda</span><span class="p">:</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">([],</span> <span class="n">maxlen</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">queue_length</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">append</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">callback</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">callback</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_call_batch_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">hook</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper function for all batch_{begin | end} methods.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="k">return</span>
    <span class="n">hook_name</span> <span class="o">=</span> <span class="s1">&#39;on_</span><span class="si">{mode}</span><span class="s1">_batch_</span><span class="si">{hook}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">hook</span><span class="o">=</span><span class="n">hook</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">hook</span> <span class="o">==</span> <span class="s1">&#39;begin&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_t_enter_batch</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">hook</span> <span class="o">==</span> <span class="s1">&#39;end&#39;</span><span class="p">:</span>
      <span class="c1"># Batch is ending, calculate batch time.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_delta_t_batch</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_t_enter_batch</span>

    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">t_before_callbacks</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">batch_hook</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">)</span>
      <span class="n">batch_hook</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_delta_ts</span><span class="p">[</span><span class="n">hook_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t_before_callbacks</span><span class="p">)</span>

    <span class="n">delta_t_median</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_delta_ts</span><span class="p">[</span><span class="n">hook_name</span><span class="p">])</span>
    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_delta_t_batch</span> <span class="o">&gt;</span> <span class="mf">0.</span> <span class="ow">and</span>
        <span class="n">delta_t_median</span> <span class="o">&gt;</span> <span class="mf">0.95</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_delta_t_batch</span> <span class="ow">and</span> <span class="n">delta_t_median</span> <span class="o">&gt;</span> <span class="mf">0.1</span><span class="p">):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
          <span class="s1">&#39;Method (</span><span class="si">%s</span><span class="s1">) is slow compared &#39;</span>
          <span class="s1">&#39;to the batch update (</span><span class="si">%f</span><span class="s1">). Check your callbacks.&#39;</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">,</span>
          <span class="n">delta_t_median</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_call_begin_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper function for on_{train|test|predict}_begin methods.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_test_begin</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_predict_begin</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_call_end_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper function for on_{train|test|predict}_end methods.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_test_end</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_predict_end</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="s1">&#39;begin&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="s1">&#39;end&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_epoch_begin` methods of its callbacks.</span>

<span class="sd">    This function should only be called during TRAIN mode.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        epoch: integer, index of epoch.</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_epoch_begin</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reset_batch_timing</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_epoch_end` methods of its callbacks.</span>

<span class="sd">    This function should only be called during TRAIN mode.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        epoch: integer, index of epoch.</span>
<span class="sd">        logs: dict, metric results for this training epoch, and for the</span>
<span class="sd">          validation epoch if validation is performed. Validation result keys</span>
<span class="sd">          are prefixed with `val_`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_epoch_end</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_train_batch_begin` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Has keys `batch` and `size` representing the current batch</span>
<span class="sd">          number and the size of the batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="s1">&#39;begin&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_train_batch_end` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Metric results for this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="s1">&#39;end&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_test_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_test_batch_begin` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Has keys `batch` and `size` representing the current batch</span>
<span class="sd">          number and the size of the batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">,</span> <span class="s1">&#39;begin&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_test_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_test_batch_end` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Metric results for this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">,</span> <span class="s1">&#39;end&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_predict_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_predict_batch_begin` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Has keys `batch` and `size` representing the current batch</span>
<span class="sd">          number and the size of the batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span><span class="p">,</span> <span class="s1">&#39;begin&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_predict_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_predict_batch_end` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Metric results for this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span><span class="p">,</span> <span class="s1">&#39;end&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_train_begin` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_train_end` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_test_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_test_begin` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_test_begin</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_test_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_test_end` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_test_end</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_predict_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the &#39;on_predict_begin` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_predict_begin</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_predict_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_predict_end` methods of its callbacks.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_predict_end</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.Callback&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Callback</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Abstract base class used to build new callbacks.</span>

<span class="sd">  Attributes:</span>
<span class="sd">      params: dict. Training parameters</span>
<span class="sd">          (eg. verbosity, batch size, number of epochs...).</span>
<span class="sd">      model: instance of `keras.models.Model`.</span>
<span class="sd">          Reference of the model being trained.</span>
<span class="sd">      validation_data: Deprecated. Do not use.</span>

<span class="sd">  The `logs` dictionary that callback methods</span>
<span class="sd">  take as argument will contain keys for quantities relevant to</span>
<span class="sd">  the current batch or epoch.</span>

<span class="sd">  Currently, the `.fit()` method of the `Model` class</span>
<span class="sd">  will include the following quantities in the `logs` that</span>
<span class="sd">  it passes to its callbacks:</span>

<span class="sd">      on_epoch_end: logs include `acc` and `loss`, and</span>
<span class="sd">          optionally include `val_loss`</span>
<span class="sd">          (if validation is enabled in `fit`), and `val_acc`</span>
<span class="sd">          (if validation and accuracy monitoring are enabled).</span>
<span class="sd">      on_batch_begin: logs include `size`,</span>
<span class="sd">          the number of samples in the current batch.</span>
<span class="sd">      on_batch_end: logs include `loss`, and optionally `acc`</span>
<span class="sd">          (if accuracy monitoring is enabled).</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">validation_data</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="c1"># Whether this Callback should only run on the chief worker in a</span>
    <span class="c1"># Multi-Worker setting.</span>
    <span class="c1"># TODO(omalleyt): Make this attr public once solution is stable.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_chief_worker_only</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>

  <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A backwards compatibility alias for `on_train_batch_begin`.&quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A backwards compatibility alias for `on_train_batch_end`.&quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the start of an epoch.</span>

<span class="sd">    Subclasses should override for any actions to run. This function should only</span>
<span class="sd">    be called during TRAIN mode.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        epoch: integer, index of epoch.</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of an epoch.</span>

<span class="sd">    Subclasses should override for any actions to run. This function should only</span>
<span class="sd">    be called during TRAIN mode.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        epoch: integer, index of epoch.</span>
<span class="sd">        logs: dict, metric results for this training epoch, and for the</span>
<span class="sd">          validation epoch if validation is performed. Validation result keys</span>
<span class="sd">          are prefixed with `val_`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_train_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of a training batch in `fit` methods.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Has keys `batch` and `size` representing the current batch</span>
<span class="sd">          number and the size of the batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># For backwards compatibility.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_begin</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of a training batch in `fit` methods.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Metric results for this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># For backwards compatibility.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_end</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_test_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of a batch in `evaluate` methods.</span>

<span class="sd">    Also called at the beginning of a validation batch in the `fit`</span>
<span class="sd">    methods, if validation data is provided.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Has keys `batch` and `size` representing the current batch</span>
<span class="sd">          number and the size of the batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_test_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of a batch in `evaluate` methods.</span>

<span class="sd">    Also called at the end of a validation batch in the `fit`</span>
<span class="sd">    methods, if validation data is provided.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Metric results for this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_predict_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of a batch in `predict` methods.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Has keys `batch` and `size` representing the current batch</span>
<span class="sd">          number and the size of the batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_predict_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of a batch in `predict` methods.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        batch: integer, index of batch within the current epoch.</span>
<span class="sd">        logs: dict. Metric results for this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of training.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of training.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_test_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of evaluation or validation.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_test_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of evaluation or validation.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_predict_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of prediction.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_predict_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of prediction.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.BaseLogger&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">BaseLogger</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback that accumulates epoch averages of metrics.</span>

<span class="sd">  This callback is automatically applied to every Keras model.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      stateful_metrics: Iterable of string names of metrics that</span>
<span class="sd">          should *not* be averaged over an epoch.</span>
<span class="sd">          Metrics in this list will be logged as-is in `on_epoch_end`.</span>
<span class="sd">          All others will be averaged in `on_epoch_end`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stateful_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BaseLogger</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stateful_metrics</span> <span class="ow">or</span> <span class="p">[])</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">totals</span> <span class="o">=</span> <span class="p">{}</span>

  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="c1"># In case of distribution strategy we can potentially run multiple steps</span>
    <span class="c1"># at the same time, we should account for that in the `seen` calculation.</span>
    <span class="n">num_steps</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;num_steps&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">+=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_steps</span>

    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">v</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span> <span class="o">*</span> <span class="n">batch_size</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">logs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;metrics&#39;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">:</span>
          <span class="c1"># Make value available to next callbacks.</span>
          <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="p">:</span>
            <span class="n">logs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">logs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">seen</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.TerminateOnNaN&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">TerminateOnNaN</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback that terminates training when a NaN loss is encountered.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Batch </span><span class="si">%d</span><span class="s1">: Invalid loss, terminating training&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">batch</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">True</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.ProgbarLogger&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ProgbarLogger</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback that prints metrics to stdout.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      count_mode: One of &quot;steps&quot; or &quot;samples&quot;.</span>
<span class="sd">          Whether the progress bar should</span>
<span class="sd">          count samples seen or steps (batches) seen.</span>
<span class="sd">      stateful_metrics: Iterable of string names of metrics that</span>
<span class="sd">          should *not* be averaged over an epoch.</span>
<span class="sd">          Metrics in this list will be logged as-is.</span>
<span class="sd">          All others will be averaged over time (e.g. loss, etc).</span>

<span class="sd">  Raises:</span>
<span class="sd">      ValueError: In case of invalid `count_mode`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">count_mode</span><span class="o">=</span><span class="s1">&#39;samples&#39;</span><span class="p">,</span> <span class="n">stateful_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ProgbarLogger</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">count_mode</span> <span class="o">==</span> <span class="s1">&#39;samples&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">elif</span> <span class="n">count_mode</span> <span class="o">==</span> <span class="s1">&#39;steps&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unknown `count_mode`: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">count_mode</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stateful_metrics</span> <span class="ow">or</span> <span class="p">[])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_values</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;verbose&#39;</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;steps&#39;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;samples&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">%d</span><span class="s1">/</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span> <span class="o">=</span> <span class="n">Progbar</span><span class="p">(</span>
        <span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">stateful_metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="p">,</span>
        <span class="n">unit_name</span><span class="o">=</span><span class="s1">&#39;step&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span> <span class="k">else</span> <span class="s1">&#39;sample&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_values</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="c1"># In case of distribution strategy we can potentially run multiple steps</span>
    <span class="c1"># at the same time, we should account for that in the `seen` calculation.</span>
    <span class="n">num_steps</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;num_steps&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">+=</span> <span class="n">num_steps</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">+=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_steps</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;metrics&#39;</span><span class="p">]:</span>
      <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">logs</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_values</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">logs</span><span class="p">[</span><span class="n">k</span><span class="p">]))</span>

    <span class="c1"># Skip progbar update for the last batch;</span>
    <span class="c1"># will be handled by on_epoch_end.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seen</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_values</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;metrics&#39;</span><span class="p">]:</span>
      <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">logs</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_values</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">logs</span><span class="p">[</span><span class="n">k</span><span class="p">]))</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seen</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_values</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.History&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">History</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback that records events into a `History` object.</span>

<span class="sd">  This callback is automatically applied to</span>
<span class="sd">  every Keras model. The `History` object</span>
<span class="sd">  gets returned by the `fit` method of models.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="p">{}</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="p">[])</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.ModelCheckpoint&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ModelCheckpoint</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Save the model after every epoch.</span>

<span class="sd">  `filepath` can contain named formatting options,</span>
<span class="sd">  which will be filled the value of `epoch` and</span>
<span class="sd">  keys in `logs` (passed in `on_epoch_end`).</span>

<span class="sd">  For example: if `filepath` is `weights.{epoch:02d}-{val_loss:.2f}.hdf5`,</span>
<span class="sd">  then the model checkpoints will be saved with the epoch number and</span>
<span class="sd">  the validation loss in the filename.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      filepath: string, path to save the model file.</span>
<span class="sd">      monitor: quantity to monitor.</span>
<span class="sd">      verbose: verbosity mode, 0 or 1.</span>
<span class="sd">      save_best_only: if `save_best_only=True`, the latest best model according</span>
<span class="sd">        to the quantity monitored will not be overwritten.</span>
<span class="sd">        If `filepath` doesn&#39;t contain formatting options like `{epoch}` then</span>
<span class="sd">        `filepath` will be overwritten by each new better model.</span>
<span class="sd">      mode: one of {auto, min, max}. If `save_best_only=True`, the decision to</span>
<span class="sd">        overwrite the current save file is made based on either the maximization</span>
<span class="sd">        or the minimization of the monitored quantity. For `val_acc`, this</span>
<span class="sd">        should be `max`, for `val_loss` this should be `min`, etc. In `auto`</span>
<span class="sd">        mode, the direction is automatically inferred from the name of the</span>
<span class="sd">        monitored quantity.</span>
<span class="sd">      save_weights_only: if True, then only the model&#39;s weights will be saved</span>
<span class="sd">        (`model.save_weights(filepath)`), else the full model is saved</span>
<span class="sd">        (`model.save(filepath)`).</span>
<span class="sd">      save_freq: `&#39;epoch&#39;` or integer. When using `&#39;epoch&#39;`, the callback saves</span>
<span class="sd">        the model after each epoch. When using integer, the callback saves the</span>
<span class="sd">        model at end of a batch at which this many samples have been seen since</span>
<span class="sd">        last saving. Note that if the saving isn&#39;t aligned to epochs, the</span>
<span class="sd">        monitored metric may potentially be less reliable (it could reflect as</span>
<span class="sd">        little as 1 batch, since the metrics get reset every epoch). Defaults to</span>
<span class="sd">        `&#39;epoch&#39;`</span>
<span class="sd">      **kwargs: Additional arguments for backwards compatibility. Possible key</span>
<span class="sd">        is `period`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">filepath</span><span class="p">,</span>
               <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
               <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">save_best_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">save_weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
               <span class="n">save_freq</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span> <span class="o">=</span> <span class="n">monitor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span> <span class="o">=</span> <span class="n">filepath</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_best_only</span> <span class="o">=</span> <span class="n">save_best_only</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_weights_only</span> <span class="o">=</span> <span class="n">save_weights_only</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">=</span> <span class="n">save_freq</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epochs_since_last_save</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen_since_last_saving</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Deprecated field `load_weights_on_restart` is for loading the checkpoint</span>
    <span class="c1"># file from `filepath` at the start of `model.fit()`</span>
    <span class="c1"># TODO(rchao): Remove the arg during next breaking release.</span>
    <span class="k">if</span> <span class="s1">&#39;load_weights_on_restart&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">load_weights_on_restart</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;load_weights_on_restart&#39;</span><span class="p">]</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`load_weights_on_restart` argument is deprecated. &#39;</span>
                      <span class="s1">&#39;Please use `model.load_weights()` for loading weights &#39;</span>
                      <span class="s1">&#39;before the start of `model.fit()`.&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">load_weights_on_restart</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Deprecated field `period` is for the number of epochs between which</span>
    <span class="c1"># the model is saved.</span>
    <span class="k">if</span> <span class="s1">&#39;period&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;period&#39;</span><span class="p">]</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`period` argument is deprecated. Please use `save_freq` &#39;</span>
                      <span class="s1">&#39;to specify the frequency in number of samples seen.&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">]:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;ModelCheckpoint mode </span><span class="si">%s</span><span class="s1"> is unknown, &#39;</span>
                      <span class="s1">&#39;fallback to auto mode.&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
      <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="s1">&#39;acc&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;fmeasure&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">!=</span> <span class="s1">&#39;epoch&#39;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unrecognized save_freq: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">))</span>

    <span class="c1"># Only the chief worker writes model checkpoints, but all workers</span>
    <span class="c1"># restore checkpoint at on_train_begin().</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_chief_worker_only</span> <span class="o">=</span> <span class="kc">False</span>

  <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="c1"># Use name matching rather than `isinstance` to avoid circular dependencies.</span>
    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_weights_only</span> <span class="ow">and</span>
        <span class="ow">not</span> <span class="n">model</span><span class="o">.</span><span class="n">_is_graph_network</span> <span class="ow">and</span>  <span class="c1"># pylint: disable=protected-access</span>
        <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">!=</span> <span class="s1">&#39;Sequential&#39;</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">save_weights_only</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># pylint: disable=protected-access</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_in_multi_worker_mode</span><span class="p">():</span>
      <span class="c1"># MultiWorkerTrainingState is used to manage the training state needed</span>
      <span class="c1"># for preemption-recovery of a worker in multi-worker training.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_training_state</span> <span class="o">=</span> <span class="p">(</span>
          <span class="n">training_state</span><span class="o">.</span><span class="n">MultiWorkerTrainingState</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_training_state</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span><span class="o">.</span><span class="n">restore</span><span class="p">():</span>
        <span class="c1"># If the training state needs to be and is successfully restored,</span>
        <span class="c1"># it is recovering from a previous failure (or preemption). In such</span>
        <span class="c1"># case, do not load the weights from user specified file path.</span>
        <span class="k">return</span>

    <span class="c1"># If this is not multi worker training, restoring is not needed, or</span>
    <span class="c1"># restoring failed, check if it should load weights on restart.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights_on_restart</span><span class="p">:</span>
      <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_in_multi_worker_mode</span><span class="p">()</span> <span class="ow">or</span>
          <span class="n">multi_worker_util</span><span class="o">.</span><span class="n">should_load_checkpoint</span><span class="p">()):</span>
        <span class="n">filepath_to_load</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_get_most_recently_modified_file_matching_pattern</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="p">))</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">filepath_to_load</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span>
            <span class="n">training_state</span><span class="o">.</span><span class="n">checkpoint_exists</span><span class="p">(</span><span class="n">filepath_to_load</span><span class="p">)):</span>
          <span class="k">try</span><span class="p">:</span>
            <span class="c1"># `filepath` may contain placeholders such as `{epoch:02d}`, and</span>
            <span class="c1"># thus it attempts to load the most recently modified file with file</span>
            <span class="c1"># name matching the pattern.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">filepath_to_load</span><span class="p">)</span>
          <span class="k">except</span> <span class="p">(</span><span class="ne">IOError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Error loading file from </span><span class="si">{}</span><span class="s1">. Reason: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">filepath_to_load</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># pylint: disable=protected-access</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_in_multi_worker_mode</span><span class="p">():</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="ow">or</span> <span class="nb">getattr</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;_successful_loop_finish&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
        <span class="c1"># In multi-worker training, on successful exit of training, delete the</span>
        <span class="c1"># training state backup file that was saved for the purpose of worker</span>
        <span class="c1"># recovery.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span><span class="o">.</span><span class="n">delete_backup</span><span class="p">()</span>
        <span class="c1"># Restore the training state so the model is ready for next (possible)</span>
        <span class="c1"># multi worker training.</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_training_state</span>

  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen_since_last_saving</span> <span class="o">+=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen_since_last_saving</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_save_model</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_current_epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen_since_last_saving</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_current_epoch</span> <span class="o">=</span> <span class="n">epoch</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epochs_since_last_save</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="c1"># pylint: disable=protected-access</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">==</span> <span class="s1">&#39;epoch&#39;</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_in_multi_worker_mode</span><span class="p">():</span>
        <span class="c1"># Exclude training state variables in user-requested checkpoint file.</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span><span class="o">.</span><span class="n">untrack_vars</span><span class="p">():</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_save_model</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_save_model</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_in_multi_worker_mode</span><span class="p">():</span>
      <span class="c1"># For multi-worker training, back up the weights and current training</span>
      <span class="c1"># state for possible future recovery.</span>
      <span class="c1"># TODO(rchao): Call `back_up` at finer period such as N steps.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span><span class="o">.</span><span class="n">back_up</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Saves the model.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        epoch: the epoch this iteration is in.</span>
<span class="sd">        logs: the `logs` dict passed in to `on_batch_end` or `on_epoch_end`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">,</span>
                  <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs_since_last_save</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">period</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">epochs_since_last_save</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="n">filepath</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_path</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

      <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_best_only</span><span class="p">:</span>
          <span class="n">current</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)</span>
          <span class="k">if</span> <span class="n">current</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Can save best model only with </span><span class="si">%s</span><span class="s1"> available, &#39;</span>
                            <span class="s1">&#39;skipping.&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">):</span>
              <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Epoch </span><span class="si">%05d</span><span class="s1">: </span><span class="si">%s</span><span class="s1"> improved from </span><span class="si">%0.5f</span><span class="s1"> to </span><span class="si">%0.5f</span><span class="s1">,&#39;</span>
                      <span class="s1">&#39; saving model to </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">,</span> <span class="n">current</span><span class="p">,</span> <span class="n">filepath</span><span class="p">))</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">current</span>
              <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_weights_only</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
              <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
              <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Epoch </span><span class="si">%05d</span><span class="s1">: </span><span class="si">%s</span><span class="s1"> did not improve from </span><span class="si">%0.5f</span><span class="s1">&#39;</span> <span class="o">%</span>
                      <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Epoch </span><span class="si">%05d</span><span class="s1">: saving model to </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">filepath</span><span class="p">))</span>
          <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_weights_only</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_remove_file</span><span class="p">()</span>
      <span class="k">except</span> <span class="ne">IOError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="c1"># `e.errno` appears to be `None` so checking the content of `e.message`.</span>
        <span class="k">if</span> <span class="s1">&#39;is a directory&#39;</span> <span class="ow">in</span> <span class="n">e</span><span class="o">.</span><span class="n">message</span><span class="p">:</span>
          <span class="k">raise</span> <span class="ne">IOError</span><span class="p">(</span><span class="s1">&#39;Please specify a non-directory filepath for &#39;</span>
                        <span class="s1">&#39;ModelCheckpoint. Filepath used is an existing &#39;</span>
                        <span class="s1">&#39;directory: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">filepath</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">_get_file_path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the file path for checkpoint.&quot;&quot;&quot;</span>
    <span class="c1"># pylint: disable=protected-access</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_in_multi_worker_mode</span><span class="p">(</span>
    <span class="p">)</span> <span class="ow">or</span> <span class="n">multi_worker_util</span><span class="o">.</span><span class="n">should_save_checkpoint</span><span class="p">():</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">logs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># If this is multi-worker training, and this worker should not</span>
      <span class="c1"># save checkpoint, we use a temp filepath to store a dummy checkpoint, so</span>
      <span class="c1"># it writes to a file that will be removed at the end of `_save_model()`</span>
      <span class="c1"># call. This is because the SyncOnReadVariable needs to be synced across</span>
      <span class="c1"># all the workers in order to be read, and all workers need to initiate</span>
      <span class="c1"># that.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_temp_file_dir</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">()</span>
      <span class="n">extension</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
      <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_temp_file_dir</span><span class="p">,</span> <span class="s1">&#39;temp&#39;</span> <span class="o">+</span> <span class="n">extension</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_maybe_remove_file</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Remove the checkpoint directory in multi-worker training where this worker</span>
    <span class="c1"># should not checkpoint. It is a dummy directory previously saved for sync</span>
    <span class="c1"># distributed training.</span>

    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_in_multi_worker_mode</span><span class="p">()</span> <span class="ow">and</span>  <span class="c1"># pylint: disable=protected-access</span>
        <span class="ow">not</span> <span class="n">multi_worker_util</span><span class="o">.</span><span class="n">should_save_checkpoint</span><span class="p">()):</span>
      <span class="n">file_io</span><span class="o">.</span><span class="n">delete_recursively</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_temp_file_dir</span><span class="p">)</span>
      <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_temp_file_dir</span>

  <span class="k">def</span> <span class="nf">_get_most_recently_modified_file_matching_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pattern</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the most recently modified filepath matching pattern.</span>

<span class="sd">    Pattern may contain python formatting placeholder. If</span>
<span class="sd">    `tf.train.latest_checkpoint()` does not return None, use that; otherwise,</span>
<span class="sd">    check for most recently modified one that matches the pattern.</span>

<span class="sd">    In the rare case where there are more than one pattern-matching file having</span>
<span class="sd">    the same modified time that is most recent among all, return the filepath</span>
<span class="sd">    that is largest (by `&gt;` operator, lexicographically using the numeric</span>
<span class="sd">    equivalents). This provides a tie-breaker when multiple files are most</span>
<span class="sd">    recent. Note that a larger `filepath` can sometimes indicate a later time of</span>
<span class="sd">    modification (for instance, when epoch/batch is used as formatting option),</span>
<span class="sd">    but not necessarily (when accuracy or loss is used). The tie-breaker is</span>
<span class="sd">    put in the logic as best effort to return the most recent, and to avoid</span>
<span class="sd">    undeterministic result.</span>

<span class="sd">    Modified time of a file is obtained with `os.path.getmtime()`.</span>

<span class="sd">    This utility function is best demonstrated via an example:</span>

<span class="sd">    ```python</span>
<span class="sd">    file_pattern = &#39;f.batch{batch:02d}epoch{epoch:02d}.h5&#39;</span>
<span class="sd">    test_dir = self.get_temp_dir()</span>
<span class="sd">    path_pattern = os.path.join(test_dir, file_pattern)</span>
<span class="sd">    file_paths = [</span>
<span class="sd">        os.path.join(test_dir, file_name) for file_name in</span>
<span class="sd">        [&#39;f.batch03epoch02.h5&#39;, &#39;f.batch02epoch02.h5&#39;, &#39;f.batch01epoch01.h5&#39;]</span>
<span class="sd">    ]</span>
<span class="sd">    for file_path in file_paths:</span>
<span class="sd">      # Write something to each of the files</span>
<span class="sd">    self.assertEqual(</span>
<span class="sd">        _get_most_recently_modified_file_matching_pattern(path_pattern),</span>
<span class="sd">        file_paths[-1])</span>
<span class="sd">    ```</span>

<span class="sd">    Arguments:</span>
<span class="sd">        pattern: The file pattern that may optionally contain python placeholder</span>
<span class="sd">            such as `{epoch:02d}`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The most recently modified file&#39;s full filepath matching `pattern`. If</span>
<span class="sd">        `pattern` does not contain any placeholder, this returns the filepath</span>
<span class="sd">        that</span>
<span class="sd">        exactly matches `pattern`. Returns `None` if no match is found.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dir_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
    <span class="n">base_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
    <span class="n">base_name_regex</span> <span class="o">=</span> <span class="s1">&#39;^&#39;</span> <span class="o">+</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;{.*}&#39;</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;.*&#39;</span><span class="p">,</span> <span class="n">base_name</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;$&#39;</span>

    <span class="c1"># If tf.train.latest_checkpoint tells us there exists a latest checkpoint,</span>
    <span class="c1"># use that as it is more robust than `os.path.getmtime()`.</span>
    <span class="n">latest_tf_checkpoint</span> <span class="o">=</span> <span class="n">checkpoint_management</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="n">dir_name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">latest_tf_checkpoint</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span>
        <span class="n">base_name_regex</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">latest_tf_checkpoint</span><span class="p">)):</span>
      <span class="k">return</span> <span class="n">latest_tf_checkpoint</span>

    <span class="n">latest_mod_time</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">file_path_with_latest_mod_time</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">n_file_with_latest_mod_time</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">file_path_with_largest_file_name</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">file_io</span><span class="o">.</span><span class="n">file_exists</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
        <span class="c1"># Only consider if `file_name` matches the pattern.</span>
        <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">base_name_regex</span><span class="p">,</span> <span class="n">file_name</span><span class="p">):</span>
          <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_name</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
          <span class="n">mod_time</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getmtime</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
          <span class="k">if</span> <span class="p">(</span><span class="n">file_path_with_largest_file_name</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span>
              <span class="n">file_path</span> <span class="o">&gt;</span> <span class="n">file_path_with_largest_file_name</span><span class="p">):</span>
            <span class="n">file_path_with_largest_file_name</span> <span class="o">=</span> <span class="n">file_path</span>
          <span class="k">if</span> <span class="n">mod_time</span> <span class="o">&gt;</span> <span class="n">latest_mod_time</span><span class="p">:</span>
            <span class="n">latest_mod_time</span> <span class="o">=</span> <span class="n">mod_time</span>
            <span class="n">file_path_with_latest_mod_time</span> <span class="o">=</span> <span class="n">file_path</span>
            <span class="c1"># In the case a file with later modified time is found, reset</span>
            <span class="c1"># the counter for the number of files with latest modified time.</span>
            <span class="n">n_file_with_latest_mod_time</span> <span class="o">=</span> <span class="mi">1</span>
          <span class="k">elif</span> <span class="n">mod_time</span> <span class="o">==</span> <span class="n">latest_mod_time</span><span class="p">:</span>
            <span class="c1"># In the case a file has modified time tied with the most recent,</span>
            <span class="c1"># increment the counter for the number of files with latest modified</span>
            <span class="c1"># time by 1.</span>
            <span class="n">n_file_with_latest_mod_time</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">n_file_with_latest_mod_time</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="c1"># Return the sole file that has most recent modified time.</span>
      <span class="k">return</span> <span class="n">file_path_with_latest_mod_time</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># If there are more than one file having latest modified time, return</span>
      <span class="c1"># the file path with the largest file name.</span>
      <span class="k">return</span> <span class="n">file_path_with_largest_file_name</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.EarlyStopping&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">EarlyStopping</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Stop training when a monitored quantity has stopped improving.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      monitor: Quantity to be monitored.</span>
<span class="sd">      min_delta: Minimum change in the monitored quantity</span>
<span class="sd">          to qualify as an improvement, i.e. an absolute</span>
<span class="sd">          change of less than min_delta, will count as no</span>
<span class="sd">          improvement.</span>
<span class="sd">      patience: Number of epochs with no improvement</span>
<span class="sd">          after which training will be stopped.</span>
<span class="sd">      verbose: verbosity mode.</span>
<span class="sd">      mode: One of `{&quot;auto&quot;, &quot;min&quot;, &quot;max&quot;}`. In `min` mode,</span>
<span class="sd">          training will stop when the quantity</span>
<span class="sd">          monitored has stopped decreasing; in `max`</span>
<span class="sd">          mode it will stop when the quantity</span>
<span class="sd">          monitored has stopped increasing; in `auto`</span>
<span class="sd">          mode, the direction is automatically inferred</span>
<span class="sd">          from the name of the monitored quantity.</span>
<span class="sd">      baseline: Baseline value for the monitored quantity.</span>
<span class="sd">          Training will stop if the model doesn&#39;t show improvement over the</span>
<span class="sd">          baseline.</span>
<span class="sd">      restore_best_weights: Whether to restore model weights from</span>
<span class="sd">          the epoch with the best value of the monitored quantity.</span>
<span class="sd">          If False, the model weights obtained at the last step of</span>
<span class="sd">          training are used.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  callback = tf.keras.callbacks.EarlyStopping(monitor=&#39;val_loss&#39;, patience=3)</span>
<span class="sd">  # This callback will stop the training when there is no improvement in</span>
<span class="sd">  # the validation loss for three consecutive epochs.</span>
<span class="sd">  model.fit(data, labels, epochs=100, callbacks=[callback],</span>
<span class="sd">      validation_data=(val_data, val_labels))</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
               <span class="n">min_delta</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">patience</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
               <span class="n">baseline</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">EarlyStopping</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span> <span class="o">=</span> <span class="n">monitor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">baseline</span> <span class="o">=</span> <span class="n">baseline</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">min_delta</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">restore_best_weights</span> <span class="o">=</span> <span class="n">restore_best_weights</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">]:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;EarlyStopping mode </span><span class="si">%s</span><span class="s1"> is unknown, &#39;</span>
                      <span class="s1">&#39;fallback to auto mode.&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
      <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="s1">&#39;acc&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">*=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># Allow instances to be re-used</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">baseline</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">baseline</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span> <span class="k">else</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">current</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_monitor_value</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">current</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span><span class="p">(</span><span class="n">current</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">current</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restore_best_weights</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restore_best_weights</span><span class="p">:</span>
          <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Restoring model weights from the end of the best epoch.&#39;</span><span class="p">)</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">%05d</span><span class="s1">: early stopping&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">get_monitor_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">monitor_value</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">monitor_value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Early stopping conditioned on metric `</span><span class="si">%s</span><span class="s1">` &#39;</span>
                      <span class="s1">&#39;which is not available. Available metrics are: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>
    <span class="k">return</span> <span class="n">monitor_value</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.RemoteMonitor&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">RemoteMonitor</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback used to stream events to a server.</span>

<span class="sd">  Requires the `requests` library.</span>
<span class="sd">  Events are sent to `root + &#39;/publish/epoch/end/&#39;` by default. Calls are</span>
<span class="sd">  HTTP POST, with a `data` argument which is a</span>
<span class="sd">  JSON-encoded dictionary of event data.</span>
<span class="sd">  If send_as_json is set to True, the content type of the request will be</span>
<span class="sd">  application/json. Otherwise the serialized JSON will be sent within a form.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      root: String; root url of the target server.</span>
<span class="sd">      path: String; path relative to `root` to which the events will be sent.</span>
<span class="sd">      field: String; JSON field under which the data will be stored.</span>
<span class="sd">          The field is used only if the payload is sent within a form</span>
<span class="sd">          (i.e. send_as_json is set to False).</span>
<span class="sd">      headers: Dictionary; optional custom HTTP headers.</span>
<span class="sd">      send_as_json: Boolean; whether the request should be</span>
<span class="sd">          sent as application/json.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">root</span><span class="o">=</span><span class="s1">&#39;http://localhost:9000&#39;</span><span class="p">,</span>
               <span class="n">path</span><span class="o">=</span><span class="s1">&#39;/publish/epoch/end/&#39;</span><span class="p">,</span>
               <span class="n">field</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">,</span>
               <span class="n">headers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">send_as_json</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">RemoteMonitor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">root</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">field</span> <span class="o">=</span> <span class="n">field</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">headers</span> <span class="o">=</span> <span class="n">headers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">send_as_json</span> <span class="o">=</span> <span class="n">send_as_json</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">requests</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s1">&#39;RemoteMonitor requires the `requests` library.&#39;</span><span class="p">)</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">send</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">send</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="n">send</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">send_as_json</span><span class="p">:</span>
        <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">send</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">headers</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">send</span><span class="p">)},</span>
            <span class="n">headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">headers</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">RequestException</span><span class="p">:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Warning: could not reach RemoteMonitor &#39;</span>
                      <span class="s1">&#39;root server at &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">))</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.LearningRateScheduler&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LearningRateScheduler</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Learning rate scheduler.</span>

<span class="sd">  Arguments:</span>
<span class="sd">      schedule: a function that takes an epoch index as input</span>
<span class="sd">          (integer, indexed from 0) and returns a new</span>
<span class="sd">          learning rate as output (float).</span>
<span class="sd">      verbose: int. 0: quiet, 1: update messages.</span>

<span class="sd">  ```python</span>
<span class="sd">  # This function keeps the learning rate at 0.001 for the first ten epochs</span>
<span class="sd">  # and decreases it exponentially after that.</span>
<span class="sd">  def scheduler(epoch):</span>
<span class="sd">    if epoch &lt; 10:</span>
<span class="sd">      return 0.001</span>
<span class="sd">    else:</span>
<span class="sd">      return 0.001 * tf.math.exp(0.1 * (10 - epoch))</span>

<span class="sd">  callback = tf.keras.callbacks.LearningRateScheduler(scheduler)</span>
<span class="sd">  model.fit(data, labels, epochs=100, callbacks=[callback],</span>
<span class="sd">            validation_data=(val_data, val_labels))</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">schedule</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">LearningRateScheduler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">schedule</span> <span class="o">=</span> <span class="n">schedule</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Optimizer must have a &quot;lr&quot; attribute.&#39;</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>  <span class="c1"># new API</span>
      <span class="n">lr</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">))</span>
      <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>  <span class="c1"># Support for old API for backward compatibility</span>
      <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The output of the &quot;schedule&quot; function &#39;</span>
                       <span class="s1">&#39;should be float.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">lr</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The dtype of Tensor should be float&#39;</span><span class="p">)</span>
    <span class="n">K</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">K</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">lr</span><span class="p">))</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Epoch </span><span class="si">%05d</span><span class="s1">: LearningRateScheduler reducing learning &#39;</span>
            <span class="s1">&#39;rate to </span><span class="si">%s</span><span class="s1">.&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">lr</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">logs</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.TensorBoard&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[])</span>
<span class="k">class</span> <span class="nc">TensorBoard</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="c1"># pylint: disable=line-too-long</span>
  <span class="sd">&quot;&quot;&quot;Enable visualizations for TensorBoard.</span>

<span class="sd">  TensorBoard is a visualization tool provided with TensorFlow.</span>

<span class="sd">  This callback logs events for TensorBoard, including:</span>

<span class="sd">  * Metrics summary plots</span>
<span class="sd">  * Training graph visualization</span>
<span class="sd">  * Activation histograms</span>
<span class="sd">  * Sampled profiling</span>

<span class="sd">  If you have installed TensorFlow with pip, you should be able</span>
<span class="sd">  to launch TensorBoard from the command line:</span>

<span class="sd">  ```sh</span>
<span class="sd">  tensorboard --logdir=path_to_your_logs</span>
<span class="sd">  ```</span>

<span class="sd">  You can find more information about TensorBoard</span>
<span class="sd">  [here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).</span>

<span class="sd">  Arguments:</span>
<span class="sd">      log_dir: the path of the directory where to save the log files to be</span>
<span class="sd">        parsed by TensorBoard.</span>
<span class="sd">      histogram_freq: frequency (in epochs) at which to compute activation and</span>
<span class="sd">        weight histograms for the layers of the model. If set to 0, histograms</span>
<span class="sd">        won&#39;t be computed. Validation data (or split) must be specified for</span>
<span class="sd">        histogram visualizations.</span>
<span class="sd">      write_graph: whether to visualize the graph in TensorBoard. The log file</span>
<span class="sd">        can become quite large when write_graph is set to True.</span>
<span class="sd">      write_images: whether to write model weights to visualize as image in</span>
<span class="sd">        TensorBoard.</span>
<span class="sd">      update_freq: `&#39;batch&#39;` or `&#39;epoch&#39;` or integer. When using `&#39;batch&#39;`,</span>
<span class="sd">        writes the losses and metrics to TensorBoard after each batch. The same</span>
<span class="sd">        applies for `&#39;epoch&#39;`. If using an integer, let&#39;s say `1000`, the</span>
<span class="sd">        callback will write the metrics and losses to TensorBoard every 1000</span>
<span class="sd">        batches. Note that writing too frequently to TensorBoard can slow down</span>
<span class="sd">        your training.</span>
<span class="sd">      profile_batch: Profile the batch to sample compute characteristics. By</span>
<span class="sd">        default, it will profile the second batch. Set profile_batch=0 to</span>
<span class="sd">        disable profiling. Must run in TensorFlow eager mode.</span>
<span class="sd">      embeddings_freq: frequency (in epochs) at which embedding layers will</span>
<span class="sd">        be visualized. If set to 0, embeddings won&#39;t be visualized.</span>
<span class="sd">      embeddings_metadata: a dictionary which maps layer name to a file name in</span>
<span class="sd">        which metadata for this embedding layer is saved. See the</span>
<span class="sd">        [details](</span>
<span class="sd">          https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional)</span>
<span class="sd">        about metadata files format. In case if the same metadata file is</span>
<span class="sd">        used for all embedding layers, string can be passed.</span>

<span class="sd">  Raises:</span>
<span class="sd">      ValueError: If histogram_freq is set and no validation data is provided.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1"># pylint: enable=line-too-long</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">log_dir</span><span class="o">=</span><span class="s1">&#39;logs&#39;</span><span class="p">,</span>
               <span class="n">histogram_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">write_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">write_images</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">update_freq</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span>
               <span class="n">profile_batch</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
               <span class="n">embeddings_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">embeddings_metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">TensorBoard</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_validate_kwargs</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">log_dir</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">histogram_freq</span> <span class="o">=</span> <span class="n">histogram_freq</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">write_graph</span> <span class="o">=</span> <span class="n">write_graph</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">write_images</span> <span class="o">=</span> <span class="n">write_images</span>
    <span class="k">if</span> <span class="n">update_freq</span> <span class="o">==</span> <span class="s1">&#39;batch&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">=</span> <span class="n">update_freq</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_freq</span> <span class="o">=</span> <span class="n">embeddings_freq</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span> <span class="o">=</span> <span class="n">embeddings_metadata</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_samples_seen_at_last_write</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_current_batch</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># A collection of file writers currently in use, to be closed when</span>
    <span class="c1"># training ends for this callback. Writers are keyed by the</span>
    <span class="c1"># directory name under the root logdir: e.g., &quot;train&quot; or</span>
    <span class="c1"># &quot;validation&quot;.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span> <span class="o">=</span> <span class="s1">&#39;train&#39;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_validation_run_name</span> <span class="o">=</span> <span class="s1">&#39;validation&#39;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_profile_batch</span> <span class="o">=</span> <span class="n">profile_batch</span>
    <span class="c1"># True when a trace is running.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="o">=</span> <span class="kc">False</span>

  <span class="k">def</span> <span class="nf">_validate_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Handle arguments were supported in V1.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;write_grads&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`write_grads` will be ignored in TensorFlow 2.0 &#39;</span>
                      <span class="s1">&#39;for the `TensorBoard` Callback.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`batch_size` is no longer needed in the &#39;</span>
                      <span class="s1">&#39;`TensorBoard` Callback and will be ignored &#39;</span>
                      <span class="s1">&#39;in TensorFlow 2.0.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;embeddings_layer_names&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`embeddings_layer_names` is not supported in &#39;</span>
                      <span class="s1">&#39;TensorFlow 2.0. Instead, all `Embedding` layers &#39;</span>
                      <span class="s1">&#39;will be visualized.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;embeddings_data&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`embeddings_data` is not supported in TensorFlow &#39;</span>
                      <span class="s1">&#39;2.0. Instead, all `Embedding` variables will be &#39;</span>
                      <span class="s1">&#39;visualized.&#39;</span><span class="p">)</span>

    <span class="n">unrecognized_kwargs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">-</span> <span class="p">{</span>
        <span class="s1">&#39;write_grads&#39;</span><span class="p">,</span> <span class="s1">&#39;embeddings_layer_names&#39;</span><span class="p">,</span> <span class="s1">&#39;embeddings_data&#39;</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span>
    <span class="p">}</span>

    <span class="c1"># Only allow kwargs that were supported in V1.</span>
    <span class="k">if</span> <span class="n">unrecognized_kwargs</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unrecognized arguments in `TensorBoard` &#39;</span>
                       <span class="s1">&#39;Callback: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">unrecognized_kwargs</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets Keras model and writes graph if specified.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="c1"># TensorBoard callback involves writing a summary file in a</span>
    <span class="c1"># possibly distributed settings.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_log_write_dir</span> <span class="o">=</span> <span class="n">distributed_file_utils</span><span class="o">.</span><span class="n">write_dirpath</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_get_distribution_strategy</span><span class="p">())</span>  <span class="c1"># pylint: disable=protected-access</span>

    <span class="k">with</span> <span class="n">context</span><span class="o">.</span><span class="n">eager_mode</span><span class="p">():</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_close_writers</span><span class="p">()</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_graph</span><span class="p">:</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_writer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span><span class="p">)</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
          <span class="k">with</span> <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">always_record_summaries</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">model</span><span class="o">.</span><span class="n">run_eagerly</span><span class="p">:</span>
              <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">graph</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">get_graph</span><span class="p">(),</span> <span class="n">step</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="n">summary_writable</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_is_graph_network</span> <span class="ow">or</span>  <span class="c1"># pylint: disable=protected-access</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;Sequential&#39;</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>
            <span class="k">if</span> <span class="n">summary_writable</span><span class="p">:</span>
              <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">keras_model</span><span class="p">(</span><span class="s1">&#39;keras&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_freq</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_configure_embeddings</span><span class="p">()</span>

    <span class="n">summary_state</span> <span class="o">=</span> <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">_summary_state</span>  <span class="c1"># pylint: disable=protected-access</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_prev_summary_recording</span> <span class="o">=</span> <span class="n">summary_state</span><span class="o">.</span><span class="n">is_recording</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_prev_summary_writer</span> <span class="o">=</span> <span class="n">summary_state</span><span class="o">.</span><span class="n">writer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_prev_summary_step</span> <span class="o">=</span> <span class="n">summary_state</span><span class="o">.</span><span class="n">step</span>

  <span class="k">def</span> <span class="nf">_configure_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Configure the Projector for embeddings.&quot;&quot;&quot;</span>
    <span class="c1"># TODO(omalleyt): Add integration tests.</span>
    <span class="kn">from</span> <span class="nn">tensorflow.python.keras.layers</span> <span class="kn">import</span> <span class="n">embeddings</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="kn">from</span> <span class="nn">tensorboard.plugins</span> <span class="kn">import</span> <span class="n">projector</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s1">&#39;Failed to import TensorBoard. Please make sure that &#39;</span>
                        <span class="s1">&#39;TensorBoard integration is complete.&quot;&#39;</span><span class="p">)</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">projector</span><span class="o">.</span><span class="n">ProjectorConfig</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">Embedding</span><span class="p">):</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="n">embedding</span><span class="o">.</span><span class="n">tensor_name</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">name</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">embedding</span><span class="o">.</span><span class="n">metadata_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">embedding</span><span class="o">.</span><span class="n">metadata_path</span><span class="p">:</span>
              <span class="n">embedding</span><span class="o">.</span><span class="n">metadata_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unrecognized `Embedding` layer names passed to &#39;</span>
                       <span class="s1">&#39;`keras.callbacks.TensorBoard` `embeddings_metadata` &#39;</span>
                       <span class="s1">&#39;argument: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>

    <span class="k">class</span> <span class="nc">DummyWriter</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
      <span class="sd">&quot;&quot;&quot;Dummy writer to conform to `Projector` API.&quot;&quot;&quot;</span>

      <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logdir</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logdir</span> <span class="o">=</span> <span class="n">logdir</span>

      <span class="k">def</span> <span class="nf">get_logdir</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">logdir</span>

    <span class="n">writer</span> <span class="o">=</span> <span class="n">DummyWriter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_write_dir</span><span class="p">)</span>
    <span class="n">projector</span><span class="o">.</span><span class="n">visualize_embeddings</span><span class="p">(</span><span class="n">writer</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_close_writers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Close all remaining open file writers owned by this callback.</span>

<span class="sd">    If there are no such file writers, this is a no-op.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">context</span><span class="o">.</span><span class="n">eager_mode</span><span class="p">():</span>
      <span class="k">for</span> <span class="n">writer</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">itervalues</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">):</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_get_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">writer_name</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get a summary writer for the given subdirectory under the logdir.</span>

<span class="sd">    A writer will be created if it does not yet exist.</span>

<span class="sd">    Arguments:</span>
<span class="sd">      writer_name: The name of the directory for which to create or</span>
<span class="sd">        retrieve a writer. Should be either `self._train_run_name` or</span>
<span class="sd">        `self._validation_run_name`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `SummaryWriter` object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">writer_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">:</span>
      <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_write_dir</span><span class="p">,</span> <span class="n">writer_name</span><span class="p">)</span>
      <span class="n">writer</span> <span class="o">=</span> <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">create_file_writer_v2</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">[</span><span class="n">writer_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">writer</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">[</span><span class="n">writer_name</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">_set_default_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">writer_name</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets the default writer for custom batch-level summaries.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">==</span> <span class="s1">&#39;epoch&#39;</span><span class="p">:</span>
      <span class="c1"># Writer is only used for custom summaries, which are written</span>
      <span class="c1"># batch-by-batch.</span>
      <span class="k">return</span>

    <span class="n">step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_batches_seen</span><span class="p">[</span><span class="n">writer_name</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_should_record</span><span class="p">():</span>
      <span class="k">return</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">step</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="n">summary_state</span> <span class="o">=</span> <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">_summary_state</span>  <span class="c1"># pylint: disable=protected-access</span>
    <span class="n">summary_state</span><span class="o">.</span><span class="n">is_recording</span> <span class="o">=</span> <span class="n">_should_record</span>
    <span class="n">summary_state</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_writer</span><span class="p">(</span><span class="n">writer_name</span><span class="p">)</span>
    <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">set_step</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_init_batch_steps</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create the total batch counters.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">ops</span><span class="o">.</span><span class="n">executing_eagerly_outside_functions</span><span class="p">():</span>
      <span class="c1"># Variables are needed for the `step` value of custom tf.summaries</span>
      <span class="c1"># to be updated inside a tf.function.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_total_batches_seen</span> <span class="o">=</span> <span class="p">{</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span><span class="p">:</span> <span class="n">variables</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="p">),</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_validation_run_name</span><span class="p">:</span> <span class="n">variables</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int64&#39;</span><span class="p">)</span>
      <span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># Custom tf.summaries are not supported in legacy graph mode.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_total_batches_seen</span> <span class="o">=</span> <span class="p">{</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_validation_run_name</span><span class="p">:</span> <span class="mi">0</span>
      <span class="p">}</span>

  <span class="k">def</span> <span class="nf">_increment_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">writer_name</span><span class="p">):</span>
    <span class="n">step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_batches_seen</span><span class="p">[</span><span class="n">writer_name</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">variables</span><span class="o">.</span><span class="n">Variable</span><span class="p">):</span>
      <span class="n">step</span><span class="o">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_total_batches_seen</span><span class="p">[</span><span class="n">writer_name</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_init_batch_steps</span><span class="p">()</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_profile_batch</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">trace_on</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">profiler</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="k">def</span> <span class="nf">on_test_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_set_default_writer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_validation_run_name</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Writes scalar summaries for metrics on every training batch.</span>

<span class="sd">    Performs profiling if current batch is in profiler_batches.</span>

<span class="sd">    Arguments:</span>
<span class="sd">      batch: Integer, index of batch within the current epoch.</span>
<span class="sd">      logs: Dict. Metric results for this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">==</span> <span class="s1">&#39;epoch&#39;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_profile_batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span>

    <span class="c1"># Don&#39;t output batch_size and batch number as TensorBoard summaries</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">train_batches</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_batches_seen</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span><span class="p">]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">!=</span> <span class="s1">&#39;epoch&#39;</span> <span class="ow">and</span> <span class="n">batch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_log_metrics</span><span class="p">(</span><span class="n">logs</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;batch_&#39;</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">train_batches</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_increment_step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_log_trace</span><span class="p">()</span>
      <span class="k">elif</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="ow">and</span>
            <span class="n">math_ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">train_batches</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_profile_batch</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_enable_trace</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_test_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">==</span> <span class="s1">&#39;epoch&#39;</span><span class="p">:</span>
      <span class="k">return</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_increment_step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_validation_run_name</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_set_default_writer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Runs metrics and histogram summaries at epoch end.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_log_metrics</span><span class="p">(</span><span class="n">logs</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;epoch_&#39;</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">histogram_freq</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">histogram_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_log_weights</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_freq</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_log_embeddings</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_log_trace</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_close_writers</span><span class="p">()</span>

    <span class="n">summary_state</span> <span class="o">=</span> <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">_summary_state</span>  <span class="c1"># pylint: disable=protected-access</span>
    <span class="n">summary_state</span><span class="o">.</span><span class="n">is_recording</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prev_summary_recording</span>
    <span class="n">summary_state</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prev_summary_writer</span>
    <span class="n">summary_state</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prev_summary_step</span>

    <span class="c1"># Safely remove the unneeded temp files.</span>
    <span class="n">distributed_file_utils</span><span class="o">.</span><span class="n">remove_temp_dirpath</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_get_distribution_strategy</span><span class="p">())</span>  <span class="c1"># pylint: disable=protected-access</span>

  <span class="k">def</span> <span class="nf">_enable_trace</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
      <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">trace_on</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">profiler</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="k">def</span> <span class="nf">_log_trace</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Logs the trace graph to TensorBoard.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
      <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_writer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span><span class="p">)</span><span class="o">.</span><span class="n">as_default</span><span class="p">(),</span> \
          <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">always_record_summaries</span><span class="p">():</span>
        <span class="c1"># TODO(b/126388999): Remove step info in the summary name.</span>
        <span class="n">step</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_total_batches_seen</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span><span class="p">])</span>
        <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">trace_export</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;batch_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">step</span><span class="p">,</span>
            <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">,</span>
            <span class="n">profiler_outdir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_write_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="o">=</span> <span class="kc">False</span>

  <span class="k">def</span> <span class="nf">_log_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Writes metrics out as custom scalar summaries.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        logs: Dict. Keys are scalar summary names, values are NumPy scalars.</span>
<span class="sd">        prefix: String. The prefix to apply to the scalar summary names.</span>
<span class="sd">        step: Int. The global step to use for TensorBoard.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">logs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">logs</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># Group metrics by the name of their associated file writer. Values</span>
    <span class="c1"># are lists of metrics, as (name, scalar_value) pairs.</span>
    <span class="n">logs_by_writer</span> <span class="o">=</span> <span class="p">{</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span><span class="p">:</span> <span class="p">[],</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validation_run_name</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">}</span>
    <span class="n">validation_prefix</span> <span class="o">=</span> <span class="s1">&#39;val_&#39;</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;batch&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="s1">&#39;num_steps&#39;</span><span class="p">):</span>
        <span class="c1"># Scrub non-metric items.</span>
        <span class="k">continue</span>
      <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">validation_prefix</span><span class="p">):</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_prefix</span><span class="p">):]</span>
        <span class="n">writer_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validation_run_name</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">writer_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span>
      <span class="n">name</span> <span class="o">=</span> <span class="n">prefix</span> <span class="o">+</span> <span class="n">name</span>  <span class="c1"># assign batch or epoch prefix</span>
      <span class="n">logs_by_writer</span><span class="p">[</span><span class="n">writer_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">))</span>

    <span class="k">with</span> <span class="n">context</span><span class="o">.</span><span class="n">eager_mode</span><span class="p">():</span>
      <span class="k">with</span> <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">always_record_summaries</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">writer_name</span> <span class="ow">in</span> <span class="n">logs_by_writer</span><span class="p">:</span>
          <span class="n">these_logs</span> <span class="o">=</span> <span class="n">logs_by_writer</span><span class="p">[</span><span class="n">writer_name</span><span class="p">]</span>
          <span class="k">if</span> <span class="ow">not</span> <span class="n">these_logs</span><span class="p">:</span>
            <span class="c1"># Don&#39;t create a &quot;validation&quot; events file if we don&#39;t</span>
            <span class="c1"># actually have any validation data.</span>
            <span class="k">continue</span>
          <span class="n">writer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_writer</span><span class="p">(</span><span class="n">writer_name</span><span class="p">)</span>
          <span class="k">with</span> <span class="n">writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">these_logs</span><span class="p">:</span>
              <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_log_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Logs the weights of the Model to TensorBoard.&quot;&quot;&quot;</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_writer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_run_name</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">context</span><span class="o">.</span><span class="n">eager_mode</span><span class="p">(),</span> \
          <span class="n">writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">(),</span> \
          <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">always_record_summaries</span><span class="p">():</span>
      <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">weights</span><span class="p">:</span>
          <span class="n">weight_name</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="s1">&#39;_&#39;</span><span class="p">)</span>
          <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">init_scope</span><span class="p">():</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
          <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">weight_name</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
          <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_images</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_weight_as_image</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">weight_name</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
      <span class="n">writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_log_weight_as_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">weight_name</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Logs a weight as a TensorBoard image.&quot;&quot;&quot;</span>
    <span class="n">w_img</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Bias case</span>
      <span class="n">w_img</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">w_img</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Dense layer kernel case</span>
      <span class="k">if</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">w_img</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
      <span class="n">w_img</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">w_img</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>  <span class="c1"># ConvNet case</span>
      <span class="k">if</span> <span class="n">K</span><span class="o">.</span><span class="n">image_data_format</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;channels_last&#39;</span><span class="p">:</span>
        <span class="c1"># Switch to channels_first to display every kernel as a separate</span>
        <span class="c1"># image.</span>
        <span class="n">w_img</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">w_img</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
      <span class="n">w_img</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">w_img</span><span class="p">,</span> <span class="p">[</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="mi">1</span><span class="p">])</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
    <span class="c1"># Not possible to handle 3D convnets etc.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span> <span class="ow">and</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]:</span>
      <span class="n">summary_ops_v2</span><span class="o">.</span><span class="n">image</span><span class="p">(</span><span class="n">weight_name</span><span class="p">,</span> <span class="n">w_img</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_log_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="n">embeddings_ckpt</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_write_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span>
                                   <span class="s1">&#39;keras_embedding.ckpt-</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">embeddings_ckpt</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.ReduceLROnPlateau&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ReduceLROnPlateau</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Reduce learning rate when a metric has stopped improving.</span>

<span class="sd">  Models often benefit from reducing the learning rate by a factor</span>
<span class="sd">  of 2-10 once learning stagnates. This callback monitors a</span>
<span class="sd">  quantity and if no improvement is seen for a &#39;patience&#39; number</span>
<span class="sd">  of epochs, the learning rate is reduced.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  reduce_lr = ReduceLROnPlateau(monitor=&#39;val_loss&#39;, factor=0.2,</span>
<span class="sd">                                patience=5, min_lr=0.001)</span>
<span class="sd">  model.fit(X_train, Y_train, callbacks=[reduce_lr])</span>
<span class="sd">  ```</span>

<span class="sd">  Arguments:</span>
<span class="sd">      monitor: quantity to be monitored.</span>
<span class="sd">      factor: factor by which the learning rate will be reduced. new_lr = lr *</span>
<span class="sd">        factor</span>
<span class="sd">      patience: number of epochs with no improvement after which learning rate</span>
<span class="sd">        will be reduced.</span>
<span class="sd">      verbose: int. 0: quiet, 1: update messages.</span>
<span class="sd">      mode: one of {auto, min, max}. In `min` mode, lr will be reduced when the</span>
<span class="sd">        quantity monitored has stopped decreasing; in `max` mode it will be</span>
<span class="sd">        reduced when the quantity monitored has stopped increasing; in `auto`</span>
<span class="sd">        mode, the direction is automatically inferred from the name of the</span>
<span class="sd">        monitored quantity.</span>
<span class="sd">      min_delta: threshold for measuring the new optimum, to only focus on</span>
<span class="sd">        significant changes.</span>
<span class="sd">      cooldown: number of epochs to wait before resuming normal operation after</span>
<span class="sd">        lr has been reduced.</span>
<span class="sd">      min_lr: lower bound on the learning rate.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
               <span class="n">factor</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
               <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
               <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
               <span class="n">min_delta</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
               <span class="n">cooldown</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">min_lr</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ReduceLROnPlateau</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span> <span class="o">=</span> <span class="n">monitor</span>
    <span class="k">if</span> <span class="n">factor</span> <span class="o">&gt;=</span> <span class="mf">1.0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;ReduceLROnPlateau &#39;</span> <span class="s1">&#39;does not support a factor &gt;= 1.0.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="s1">&#39;epsilon&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="n">min_delta</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;epsilon&#39;</span><span class="p">)</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`epsilon` argument is deprecated and &#39;</span>
                      <span class="s1">&#39;will be removed, use `min_delta` instead.&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">factor</span> <span class="o">=</span> <span class="n">factor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_lr</span> <span class="o">=</span> <span class="n">min_lr</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">=</span> <span class="n">min_delta</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cooldown</span> <span class="o">=</span> <span class="n">cooldown</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Cooldown counter.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Resets wait counter and cooldown counter.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">]:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Learning Rate Plateau Reducing mode </span><span class="si">%s</span><span class="s1"> is unknown, &#39;</span>
                      <span class="s1">&#39;fallback to auto mode.&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span>
    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span> <span class="ow">or</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;auto&#39;</span> <span class="ow">and</span> <span class="s1">&#39;acc&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">logs</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">current</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">current</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Reduce LR on plateau conditioned on metric `</span><span class="si">%s</span><span class="s1">` &#39;</span>
                      <span class="s1">&#39;which is not available. Available metrics are: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>

    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_cooldown</span><span class="p">():</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>

      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">current</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_cooldown</span><span class="p">():</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
          <span class="n">old_lr</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">))</span>
          <span class="k">if</span> <span class="n">old_lr</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_lr</span><span class="p">:</span>
            <span class="n">new_lr</span> <span class="o">=</span> <span class="n">old_lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">factor</span>
            <span class="n">new_lr</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">new_lr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_lr</span><span class="p">)</span>
            <span class="n">K</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">new_lr</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
              <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Epoch </span><span class="si">%05d</span><span class="s1">: ReduceLROnPlateau reducing learning &#39;</span>
                    <span class="s1">&#39;rate to </span><span class="si">%s</span><span class="s1">.&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">new_lr</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cooldown</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="k">def</span> <span class="nf">in_cooldown</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">&gt;</span> <span class="mi">0</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.CSVLogger&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">CSVLogger</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback that streams epoch results to a csv file.</span>

<span class="sd">  Supports all values that can be represented as a string,</span>
<span class="sd">  including 1D iterables such as np.ndarray.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  csv_logger = CSVLogger(&#39;training.log&#39;)</span>
<span class="sd">  model.fit(X_train, Y_train, callbacks=[csv_logger])</span>
<span class="sd">  ```</span>

<span class="sd">  Arguments:</span>
<span class="sd">      filename: filename of the csv file, e.g. &#39;run/log.csv&#39;.</span>
<span class="sd">      separator: string used to separate elements in the csv file.</span>
<span class="sd">      append: True: append if file exists (useful for continuing</span>
<span class="sd">          training). False: overwrite existing file,</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">separator</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">append</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sep</span> <span class="o">=</span> <span class="n">separator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">filename</span> <span class="o">=</span> <span class="n">filename</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">append</span> <span class="o">=</span> <span class="n">append</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">keys</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">append_header</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="n">six</span><span class="o">.</span><span class="n">PY2</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">file_flags</span> <span class="o">=</span> <span class="s1">&#39;b&#39;</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_open_args</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">file_flags</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_open_args</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;newline&#39;</span><span class="p">:</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">}</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CSVLogger</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">append</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">file_io</span><span class="o">.</span><span class="n">file_exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">):</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">file_flags</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">append_header</span> <span class="o">=</span> <span class="ow">not</span> <span class="nb">bool</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">readline</span><span class="p">()))</span>
      <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;a&#39;</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">csv_file</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span>
                            <span class="n">mode</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">file_flags</span><span class="p">,</span>
                            <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_open_args</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">handle_value</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
      <span class="n">is_zero_dim_ndarray</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">k</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">six</span><span class="o">.</span><span class="n">string_types</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">k</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">collections_abc</span><span class="o">.</span><span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_zero_dim_ndarray</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;&quot;[</span><span class="si">%s</span><span class="s1">]&quot;&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">k</span><span class="p">)))</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">k</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">keys</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>
      <span class="c1"># We set NA so that csv parsers do not fail for this last epoch.</span>
      <span class="n">logs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">k</span><span class="p">,</span> <span class="n">logs</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">logs</span> <span class="k">else</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="s1">&#39;NA&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">])</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="p">:</span>

      <span class="k">class</span> <span class="nc">CustomDialect</span><span class="p">(</span><span class="n">csv</span><span class="o">.</span><span class="n">excel</span><span class="p">):</span>
        <span class="n">delimiter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sep</span>

      <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span>
      <span class="k">if</span> <span class="n">six</span><span class="o">.</span><span class="n">PY2</span><span class="p">:</span>
        <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="n">unicode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">fieldnames</span><span class="p">]</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">csv_file</span><span class="p">,</span>
          <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">,</span>
          <span class="n">dialect</span><span class="o">=</span><span class="n">CustomDialect</span><span class="p">)</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">append_header</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

    <span class="n">row_dict</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">OrderedDict</span><span class="p">({</span><span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">})</span>
    <span class="n">row_dict</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">key</span><span class="p">,</span> <span class="n">handle_value</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="n">key</span><span class="p">]))</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">row_dict</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">csv_file</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">csv_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="kc">None</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.LambdaCallback&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LambdaCallback</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Callback for creating simple, custom callbacks on-the-fly.</span>

<span class="sd">  This callback is constructed with anonymous functions that will be called</span>
<span class="sd">  at the appropriate time. Note that the callbacks expects positional</span>
<span class="sd">  arguments, as:</span>

<span class="sd">   - `on_epoch_begin` and `on_epoch_end` expect two positional arguments:</span>
<span class="sd">      `epoch`, `logs`</span>
<span class="sd">   - `on_batch_begin` and `on_batch_end` expect two positional arguments:</span>
<span class="sd">      `batch`, `logs`</span>
<span class="sd">   - `on_train_begin` and `on_train_end` expect one positional argument:</span>
<span class="sd">      `logs`</span>

<span class="sd">  Arguments:</span>
<span class="sd">      on_epoch_begin: called at the beginning of every epoch.</span>
<span class="sd">      on_epoch_end: called at the end of every epoch.</span>
<span class="sd">      on_batch_begin: called at the beginning of every batch.</span>
<span class="sd">      on_batch_end: called at the end of every batch.</span>
<span class="sd">      on_train_begin: called at the beginning of model training.</span>
<span class="sd">      on_train_end: called at the end of model training.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  # Print the batch number at the beginning of every batch.</span>
<span class="sd">  batch_print_callback = LambdaCallback(</span>
<span class="sd">      on_batch_begin=lambda batch,logs: print(batch))</span>

<span class="sd">  # Stream the epoch loss to a file in JSON format. The file content</span>
<span class="sd">  # is not well-formed JSON but rather has a JSON object per line.</span>
<span class="sd">  import json</span>
<span class="sd">  json_log = open(&#39;loss_log.json&#39;, mode=&#39;wt&#39;, buffering=1)</span>
<span class="sd">  json_logging_callback = LambdaCallback(</span>
<span class="sd">      on_epoch_end=lambda epoch, logs: json_log.write(</span>
<span class="sd">          json.dumps({&#39;epoch&#39;: epoch, &#39;loss&#39;: logs[&#39;loss&#39;]}) + &#39;\n&#39;),</span>
<span class="sd">      on_train_end=lambda logs: json_log.close()</span>
<span class="sd">  )</span>

<span class="sd">  # Terminate some processes after having finished model training.</span>
<span class="sd">  processes = ...</span>
<span class="sd">  cleanup_callback = LambdaCallback(</span>
<span class="sd">      on_train_end=lambda logs: [</span>
<span class="sd">          p.terminate() for p in processes if p.is_alive()])</span>

<span class="sd">  model.fit(...,</span>
<span class="sd">            callbacks=[batch_print_callback,</span>
<span class="sd">                       json_logging_callback,</span>
<span class="sd">                       cleanup_callback])</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">on_epoch_begin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">on_epoch_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">on_batch_begin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">on_batch_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">on_train_begin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">on_train_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">LambdaCallback</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">on_epoch_begin</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_epoch_begin</span> <span class="o">=</span> <span class="n">on_epoch_begin</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_epoch_begin</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">on_epoch_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_epoch_end</span> <span class="o">=</span> <span class="n">on_epoch_end</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_epoch_end</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">on_batch_begin</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_begin</span> <span class="o">=</span> <span class="n">on_batch_begin</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_begin</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">on_batch_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_end</span> <span class="o">=</span> <span class="n">on_batch_end</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_end</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">on_train_begin</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_begin</span> <span class="o">=</span> <span class="n">on_train_begin</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_begin</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">on_train_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_end</span> <span class="o">=</span> <span class="n">on_train_end</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_end</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
</pre></div>

            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
    
        <li class="nav-item nav-item-0"><a href="../../../../index.html">pysparkdl  documentation</a> &#187;</li>

          <li class="nav-item nav-item-1"><a href="../../../index.html" >Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">tensorflow.python.keras.callbacks</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2016, Timothy Hunter and Joseph Bradley.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 3.2.1.
    </div>
  </body>
</html>